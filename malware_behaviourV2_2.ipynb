{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngyamfi82/emeritus/blob/master/malware_behaviourV2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYfJ_gf0Bq3L"
      },
      "source": [
        "In v2, I noticed that the ember features was built with an old versionof lief(0.9.0). Due to this our preprocessing function was failing. fix this issue we have to recompute the ember files from the original datset [we have extracted] and push it into our preprocessing pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h8ls35biqhP",
        "outputId": "965cca26-4569-4252-9171-0daecddc6647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/elastic/ember.git\n",
            "  Cloning https://github.com/elastic/ember.git to /tmp/pip-req-build-jmjmwmyw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/elastic/ember.git /tmp/pip-req-build-jmjmwmyw\n",
            "  Resolved https://github.com/elastic/ember.git to commit d97a0b523de02f3fe5ea6089d080abacab6ee931\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ember\n",
            "  Building wheel for ember (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ember: filename=ember-0.1.0-py3-none-any.whl size=13050 sha256=2c3e3ec33b8d18ee70e1aaf888460f03c0486a312152a084e69bbeff8ebcd68f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k62gi34t/wheels/7a/af/81/7e3bd4d43fd62c37273aa84e0720752df8dbc9c43700279961\n",
            "Successfully built ember\n",
            "Installing collected packages: ember\n",
            "Successfully installed ember-0.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/elastic/ember.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GvBs4kSFWkW",
        "outputId": "d8113437-6dea-45e2-fa92-70079adcc74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lief\n",
            "  Downloading lief-0.14.1-cp310-cp310-manylinux_2_28_x86_64.manylinux_2_27_x86_64.whl (2.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m2.4/2.7 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lief\n",
            "Successfully installed lief-0.14.1\n"
          ]
        }
      ],
      "source": [
        "pip install lief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbMhPowqsKW9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F99REKWuhN1l",
        "outputId": "913d52ab-853e-4081-b439-3c3597861cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ember in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "pip install ember lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOUwcqnWjDtP"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJ4DVLbFixv",
        "outputId": "7acb5633-0c33-4631-db05-5d30edd5adf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NeuromorphicComputationResearchProgram/ClarAVy\n",
            "  Cloning https://github.com/NeuromorphicComputationResearchProgram/ClarAVy to /tmp/pip-req-build-e8w0meuj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NeuromorphicComputationResearchProgram/ClarAVy /tmp/pip-req-build-e8w0meuj\n",
            "  Resolved https://github.com/NeuromorphicComputationResearchProgram/ClarAVy to commit f496ce84e4bc037215ba0152b236aefdf52f8cca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: claravy\n",
            "  Building wheel for claravy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for claravy: filename=claravy-1.0.0-py3-none-any.whl size=101798 sha256=32d4c607934d486ae7110c3010580cc65dd16f02f82e1cb532eb0eae39188ec2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nf8cbde3/wheels/ba/d9/e6/c629c37334dcf28fe2a45c5f69fd7179c92f93cf4eddc6cdd8\n",
            "Successfully built claravy\n",
            "Installing collected packages: claravy\n",
            "Successfully installed claravy-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/NeuromorphicComputationResearchProgram/ClarAVy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIH9F2jFj6o"
      },
      "source": [
        "LOADING REQUIRED LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvht8vBNhOKG"
      },
      "outputs": [],
      "source": [
        "#%% Import libraries\n",
        "import ember\n",
        "import lief\n",
        "# import claravy\n",
        "\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import json\n",
        "import os\n",
        "from IPython import get_ipython\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRUEG-dMcmvM"
      },
      "source": [
        "Genrating new ember files from our extracted dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIY6lFSQvbUO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "floz6USgheOE"
      },
      "outputs": [],
      "source": [
        "#%% Load data\n",
        "ember_meta_dir = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/ember_metadata\"\n",
        "maldict_train_file = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/train/maldict_category_train.jsonl\"\n",
        "maldict_test_file = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/test/maldict_category_test.jsonl\"\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/train\"\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUbM7_tghen5"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(ember_meta_dir, \"ember_metadata_train/train_features.jsonl\")\n",
        "test_path = os.path.join(ember_meta_dir, \"ember_metadata_test/test_features.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbxGZOT4cC2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vVnDoSzckaU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def extract_features(file_path):\n",
        "#     try:\n",
        "#         binary = lief.parse(file_path)\n",
        "#         if not binary:\n",
        "#             return None\n",
        "#         # Extract the features using ember\n",
        "#         extractor = ember.PEFeatureExtractor()\n",
        "#         features = extractor.process(binary)\n",
        "#         return features\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing file {file_path}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Directory containing your original PE files\n",
        "# data_directory = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/train/\"\n",
        "# pe_files = [os.path.join(data_directory, f) for f in os.listdir(data_directory) ]#if f.endswith('.exe')]\n",
        "\n",
        "# # Open a JSON Lines file for writing\n",
        "# with open(\"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/ember_metadata/Train_ember_features.jsonl\", \"w\") as jsonl_file:\n",
        "#     for pe_file in pe_files:\n",
        "#         features = extract_features(pe_file)\n",
        "#         if features is not None:\n",
        "#             # Convert features to a dictionary if needed\n",
        "#             if isinstance(features, np.ndarray):\n",
        "#                 features = features.tolist()\n",
        "#             # Write the features to the JSON Lines file\n",
        "#             jsonl_file.write(json.dumps(features) + \"\\n\")\n",
        "\n",
        "# print(\"Features have been written to ember_features.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xigVphQdMSC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF5HiEicclH4"
      },
      "outputs": [],
      "source": [
        "# # Define a function to extract features from a PE file [test]\n",
        "# def extract_features(file_path):\n",
        "#     try:\n",
        "#         binary = lief.parse(file_path)\n",
        "#         if not binary:\n",
        "#             return None\n",
        "#         # Extract the features using ember\n",
        "#         extractor = ember.PEFeatureExtractor()\n",
        "#         features = extractor.process(binary)\n",
        "#         return features\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing file {file_path}: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Directory containing your original PE files\n",
        "# data_directory = \"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/test/1/\"\n",
        "# pe_files = [os.path.join(data_directory, f) for f in os.listdir(data_directory) ]#if f.endswith('.exe')]\n",
        "\n",
        "# # Open a JSON Lines file for writing\n",
        "# with open(\"/content/drive/MyDrive/Colab Notebooks/MalwareDetection/ember_metadata/Test_ember_features.jsonl\", \"w\") as jsonl_file:\n",
        "#     for pe_file in pe_files:\n",
        "#         features = extract_features(pe_file)\n",
        "#         if features is not None:\n",
        "#             # Convert features to a dictionary if needed\n",
        "#             if isinstance(features, np.ndarray):\n",
        "#                 features = features.tolist()\n",
        "#             # Write the features to the JSON Lines file\n",
        "#             jsonl_file.write(json.dumps(features) + \"\\n\")\n",
        "\n",
        "# print(\"Features have been written to ember_features.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STKifqTmcldz"
      },
      "outputs": [],
      "source": [
        "def get_vec(jsonl):\n",
        "    \"\"\"Vectorize a JSON line with EMBER raw features.\n",
        "    Returns: (md5, vector)\n",
        "    \"\"\"\n",
        "    ember_meta = json.loads(jsonl)\n",
        "    md5 = ember_meta[\"md5\"]\n",
        "    extractor = ember.PEFeatureExtractor()\n",
        "    vec = extractor.process_raw_features({\"entry\": [[ember_meta['entry']]]})  # Update this line\n",
        "    return md5, vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxnG0WCFhOhX"
      },
      "outputs": [],
      "source": [
        "# def get_vec(jsonl):\n",
        "#     \"\"\"Vectorize a JSON line with EMBER raw features.\n",
        "\n",
        "#     Returns:\n",
        "#     (md5, vector)\n",
        "#     \"\"\"\n",
        "#     ember_meta = json.loads(jsonl)\n",
        "#     md5 = ember_meta[\"md5\"]\n",
        "\n",
        "\n",
        "#     extractor = ember.PEFeatureExtractor()\n",
        "#     vec = extractor.process_raw_features(ember_meta)\n",
        "#     return md5, vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs5nbjkwhd7g"
      },
      "outputs": [],
      "source": [
        "def get_tags(tag_path):\n",
        "    \"\"\"Make a dictionary mapping MD5s to ClarAVy tags.\"\"\"\n",
        "    md5_tags = {}\n",
        "    with open(tag_path, \"r\") as f:\n",
        "        for jsonl in f:\n",
        "            entry = json.loads(jsonl.strip())\n",
        "            md5 = entry[\"md5\"]\n",
        "            tags = [rank[0] for rank in entry[\"ranking\"]]\n",
        "            md5_tags[md5] = tags\n",
        "    return md5_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbf1CBcCnTXg"
      },
      "source": [
        "### DATA PREPROCESSING AND FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkzTMwvNhujR"
      },
      "outputs": [],
      "source": [
        "with open(train_path, \"r\") as f:\n",
        "    train_meta = [line.strip() for line in f]\n",
        "with open(test_path, \"r\") as f:\n",
        "    test_meta = [line.strip() for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3JPODuKhu_j"
      },
      "outputs": [],
      "source": [
        "#%% Read train/test tags\n",
        "train_md5_tags = get_tags(maldict_train_file)\n",
        "test_md5_tags = get_tags(maldict_test_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc_CdMFP2Vi6"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# def get_vec(ember_meta):\n",
        "#   raw_obj = json.loads(ember_meta)\n",
        "#   entry_name_hashed = FeatureHasher(50, input_type=\"string\").transform([[raw_obj['entry']]]).toarray()[0]\n",
        "#   return entry_name_hashed\n",
        "\n",
        "# pool = multiprocessing.Pool(4)  # adjust num_processes as needed\n",
        "# train_md5_vecs = list(pool.imap(get_vec, train_meta))\n",
        "# test_md5_vecs = list(pool.imap(get_vec, test_meta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Eaw5QcRhvUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "52b595d2-2190-4f4b-adf5-244884a9dad3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_meta' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f8c7ade8db83>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%% Vectorize EMBER metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# adjust num_processes as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_md5_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_md5_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_meta' is not defined"
          ]
        }
      ],
      "source": [
        "#%% Vectorize EMBER metadata\n",
        "pool = multiprocessing.Pool(10)  # adjust num_processes as needed\n",
        "train_md5_vecs = list(pool.imap(get_vec, train_meta))\n",
        "test_md5_vecs = list(pool.imap(get_vec, test_meta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnsLylqYhvvf"
      },
      "outputs": [],
      "source": [
        "#%% Get sizes of train and test set\n",
        "num_train = len(train_md5_vecs)\n",
        "num_test = len(test_md5_vecs)\n",
        "vec_dim = len(train_md5_vecs[0][1])\n",
        "num_labels = len(sorted_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hT-GMofnewm",
        "outputId": "c59a1af4-d236-4f91-96e3-8757e4b98a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL TRAINING AND EVALUATION\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_1TBShnjX-"
      },
      "source": [
        "### MODEL SELECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkYsN8a9h6Xp"
      },
      "outputs": [],
      "source": [
        "#%% Get X and y for train set\n",
        "X_train = np.zeros((num_train, vec_dim), dtype=np.float)\n",
        "y_train = np.zeros((num_train, num_labels))\n",
        "for i, (md5, vec) in enumerate(train_md5_vecs):\n",
        "    labels = [tag_labels[tag] for tag in train_md5_tags[md5]]\n",
        "    X_train[i,] = vec\n",
        "    for j in labels:\n",
        "        y_train[i,j] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zarq7U1hh69X"
      },
      "outputs": [],
      "source": [
        "#%% Get X and y for test set\n",
        "X_test = np.zeros((num_test, vec_dim), dtype=np.float)\n",
        "y_test = np.zeros((num_test, num_labels), dtype=np.float)\n",
        "for i, (md5, vec) in enumerate(test_md5_vecs):\n",
        "    labels = [tag_labels[tag] for tag in test_md5_tags[md5]]\n",
        "    X_test[i,] = vec\n",
        "    for j in labels:\n",
        "        y_test[i,j] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQIX6wJ_nuE1"
      },
      "source": [
        "### MODEL TRAINING AND EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wO1YWe_h7Ux"
      },
      "outputs": [],
      "source": [
        "#%% Train OvR classifier on each tag\n",
        "y_pred = np.zeros((num_test, num_labels))\n",
        "for j, tag in enumerate(sorted_tags):\n",
        "    print(\"Training classifiers on tag: {}\".format(tag))\n",
        "\n",
        "      # Get train and test sets for fold\n",
        "      y_train_tag = y_train[:, j]\n",
        "      y_test_tag = y_test[:, j]\n",
        "\n",
        "      # Train LightGBM classifier\n",
        "      train_dataset = lgb.Dataset(X_train, y_train_tag)\n",
        "      test_dataset = lgb.Dataset(X_test, y_test_tag)\n",
        "      clf = lgb.train(params, train_dataset)\n",
        "\n",
        "      # Get predictions and compute accuracy\n",
        "      predictions = clf.predict(X_test)\n",
        "      y_pred[:,j] = predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3bN0dNth7vF"
      },
      "outputs": [],
      "source": [
        "#%% Print results\n",
        "print(\"Precision\\t{} (micro)\\t{} (weighted)\".format(p_micro, p_avg))\n",
        "print(\"Recall\\t{} (micro)\\t{} (weighted)\".format(r_micro, r_avg))\n",
        "print(\"F1-Score\\t{} (micro)\\t{} (weighted)\".format(f1_micro, f1_avg))\n",
        "print(\"ROC AUC\\t{} (micro)\\t{} (weighted)\".format(micro_auc, weighted_auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwVORuQ7hIlZ"
      },
      "outputs": [],
      "source": [
        "pickle.export(\"malwareBehaviorDetection.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aft4CH7tEA0k"
      },
      "outputs": [],
      "source": [
        "model  = \"malwareBehaviorDetection.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_76iphWaD8x4"
      },
      "outputs": [],
      "source": [
        "model.predict(\"contract.exe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzhE05D_vgNq"
      },
      "outputs": [],
      "source": [
        "[\"contract.exe\", [['worm'],[13]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwwcg7QyEaBV"
      },
      "outputs": [],
      "source": [
        "[\"contract.exe\",[[\"worm\",[13],\"spyware\"[12]]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueJE7F1qoLQ1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TK83OS6oLKX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu_tVs5doLD-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkThXtLnoL3B"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}